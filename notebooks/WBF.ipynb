{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "fusion_algorithm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsqCq7oW0Q_m"
      },
      "source": [
        "!pip install ensemble_boxes"
      ],
      "id": "BsqCq7oW0Q_m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH8xtpHTchH-"
      },
      "source": [
        "# Install cocoapi\n",
        "!pip install \"git+https://github.com/kemaloksuz/LRP-Error.git#subdirectory=pycocotools\""
      ],
      "id": "wH8xtpHTchH-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFJbK5dkcv02"
      },
      "source": [
        "pip install \"git+https://github.com/kemaloksuz/LRP-Error.git#subdirectory=panopticapi\""
      ],
      "id": "cFJbK5dkcv02",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtaS64o3cvvV"
      },
      "source": [
        "pip install \"git+https://github.com/kemaloksuz/LRP-Error.git#subdirectory=pycocotools\""
      ],
      "id": "RtaS64o3cvvV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxZ3GVBJcvnu"
      },
      "source": [
        "pip install \"git+https://github.com/kemaloksuz/LRP-Error.git#subdirectory=lvis-api\""
      ],
      "id": "xxZ3GVBJcvnu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4090cd2b"
      },
      "source": [
        "# coding: utf-8\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import time\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "from multiprocessing import Pool, Process, cpu_count, Manager\n",
        "from ensemble_boxes import *\n",
        "import os\n",
        "from itertools import permutations\n",
        "from itertools import combinations\n",
        "import csv  "
      ],
      "id": "4090cd2b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1PPmGlBvebj"
      },
      "source": [
        "header = ['name', 'ap', 'weigths']\n",
        "with open('final_ensemble.csv', 'w', encoding='UTF8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    # write the header\n",
        "    writer.writerow(header)"
      ],
      "id": "S1PPmGlBvebj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDH52zNwy6Pe"
      },
      "source": [
        "csv_names=[]\n",
        "for f_name in os.listdir(\"./csv\"):\n",
        "    csv_names.append(f_name)"
      ],
      "id": "SDH52zNwy6Pe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ2V-1kqy6Rs"
      },
      "source": [
        "print(csv_names)"
      ],
      "id": "UQ2V-1kqy6Rs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77f03d94"
      },
      "source": [
        "def get_coco_annotations_data():\n",
        "    file_in = 'new_test.json'\n",
        "    images = dict()\n",
        "    with open(file_in) as json_file:\n",
        "        data = json.load(json_file)\n",
        "        for i in range(len(data['images'])):\n",
        "            image_id = data['images'][i]['id']\n",
        "            images[image_id] = data['images'][i]\n",
        "   \n",
        "    return images"
      ],
      "id": "77f03d94",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "790df416"
      },
      "source": [
        "def get_coco_score(csv_path):\n",
        "    images = get_coco_annotations_data()\n",
        "    s = pd.read_csv(csv_path, dtype={'img_id': np.str_, 'label': np.str_})\n",
        "    out = np.zeros((len(s), 7), dtype=np.float64)\n",
        "    out[:, 0] = s['img_id']\n",
        "    ids = s['img_id'].astype(np.int32).values\n",
        "    x1 = s['x1'].values\n",
        "    x2 = s['x2'].values\n",
        "    y1 = s['y1'].values\n",
        "    y2 = s['y2'].values\n",
        "\n",
        "    for i in range(len(s)):\n",
        "\n",
        "        width = images[ids[i]]['width']\n",
        "        height = images[ids[i]]['height']\n",
        "        out[i, 1] = x1[i] * width\n",
        "        out[i, 2] = y1[i] * height\n",
        "        out[i, 3] = (x2[i] - x1[i]) * width\n",
        "        out[i, 4] = (y2[i] - y1[i]) * height\n",
        "        \n",
        "    \n",
        "    out[:, 5] = s['score'].values\n",
        "    out[:, 6] = s['label'].values\n",
        "    filename = 'new_test.json'\n",
        "    coco_gt = COCO(filename)\n",
        "    \n",
        "    detections = out\n",
        "\n",
        "    image_ids = list(set(detections[:, 0]))\n",
        "    coco_dt = coco_gt.loadRes(detections)\n",
        "    coco_eval = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
        "    coco_eval.params.imgIds = image_ids\n",
        "    coco_eval.evaluate()\n",
        "    coco_eval.accumulate()\n",
        "    coco_eval.summarize()\n",
        "    coco_metrics = coco_eval.stats\n",
        "    ap=coco_metrics[1]\n",
        "\n",
        "    return ap"
      ],
      "id": "790df416",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06194b10"
      },
      "source": [
        "def process_single_id(id, res_boxes, weights, params):\n",
        "    run_type = params['run_type']\n",
        "    verbose = params['verbose']\n",
        "\n",
        "    # print('Go for ID: {}'.format(id))\n",
        "    boxes_list = []\n",
        "    scores_list = []\n",
        "    labels_list = []\n",
        "    labels_to_use_forward = dict()\n",
        "    labels_to_use_backward = dict()\n",
        "\n",
        "    for i in range(len(res_boxes[id])):\n",
        "        boxes = []\n",
        "        scores = []\n",
        "        labels = []\n",
        "\n",
        "        dt = res_boxes[id][i]\n",
        "\n",
        "        for j in range(0, len(dt)):\n",
        "            lbl = dt[j][5]\n",
        "            scr = float(dt[j][4])\n",
        "            box_x1 = float(dt[j][0])\n",
        "            box_y1 = float(dt[j][1])\n",
        "            box_x2 = float(dt[j][2])\n",
        "            box_y2 = float(dt[j][3])\n",
        "\n",
        "            if box_x1 >= box_x2:\n",
        "                if verbose:\n",
        "                    print('Problem with box x1 and x2: {}. Skip it'.format(dt[j]))\n",
        "                continue\n",
        "            if box_y1 >= box_y2:\n",
        "                if verbose:\n",
        "                    print('Problem with box y1 and y2: {}. Skip it'.format(dt[j]))\n",
        "                continue\n",
        "            if scr <= 0:\n",
        "                if verbose:\n",
        "                    print('Problem with box score: {}. Skip it'.format(dt[j]))\n",
        "                continue\n",
        "\n",
        "            boxes.append([box_x1, box_y1, box_x2, box_y2])\n",
        "            scores.append(scr)\n",
        "            if lbl not in labels_to_use_forward:\n",
        "                cur_point = len(labels_to_use_forward)\n",
        "                labels_to_use_forward[lbl] = cur_point\n",
        "                labels_to_use_backward[cur_point] = lbl\n",
        "            labels.append(labels_to_use_forward[lbl])\n",
        "\n",
        "        boxes = np.array(boxes, dtype=np.float32)\n",
        "        scores = np.array(scores, dtype=np.float32)\n",
        "        labels = np.array(labels, dtype=np.int32)\n",
        "\n",
        "        boxes_list.append(boxes)\n",
        "        scores_list.append(scores)\n",
        "        labels_list.append(labels)\n",
        "\n",
        "    # Empty predictions for all models\n",
        "    if len(boxes_list) == 0:\n",
        "        return np.array([]), np.array([]), np.array([])\n",
        "\n",
        "    if run_type == 'wbf':\n",
        "        merged_boxes, merged_scores, merged_labels = weighted_boxes_fusion(boxes_list, scores_list, labels_list,\n",
        "                                                                       weights=weights, iou_thr=params['intersection_thr'],\n",
        "                                                                       skip_box_thr=params['skip_box_thr'],\n",
        "                                                                           conf_type=params['conf_type'])\n",
        "    elif run_type == 'nms':\n",
        "        iou_thr = params['iou_thr']\n",
        "        merged_boxes, merged_scores, merged_labels = nms(boxes_list, scores_list, labels_list, weights=weights, iou_thr=iou_thr)\n",
        "    elif run_type == 'soft-nms':\n",
        "        iou_thr = params['iou_thr']\n",
        "        sigma = params['sigma']\n",
        "        thresh = params['thresh']\n",
        "        merged_boxes, merged_scores, merged_labels = soft_nms(boxes_list, scores_list, labels_list,\n",
        "                                                              weights=weights, iou_thr=iou_thr, sigma=sigma, thresh=thresh)\n",
        "    elif run_type == 'nmw':\n",
        "        merged_boxes, merged_scores, merged_labels = non_maximum_weighted(boxes_list, scores_list, labels_list,\n",
        "                                                                       weights=weights, iou_thr=params['intersection_thr'],\n",
        "                                                                       skip_box_thr=params['skip_box_thr'])\n",
        "\n",
        "    # print(len(boxes_list), len(merged_boxes))\n",
        "    if 'limit_boxes' in params:\n",
        "        limit_boxes = params['limit_boxes']\n",
        "        if len(merged_boxes) > limit_boxes:\n",
        "            merged_boxes = merged_boxes[:limit_boxes]\n",
        "            merged_scores = merged_scores[:limit_boxes]\n",
        "            merged_labels = merged_labels[:limit_boxes]\n",
        "\n",
        "    # Rename labels back\n",
        "    merged_labels_string = []\n",
        "    for m in merged_labels:\n",
        "        merged_labels_string.append(labels_to_use_backward[m])\n",
        "    merged_labels = np.array(merged_labels_string, dtype=np.str)\n",
        "\n",
        "    # Create IDs array\n",
        "    ids_list = [id] * len(merged_labels)\n",
        "\n",
        "    return merged_boxes.copy(), merged_scores.copy(), merged_labels.copy(), ids_list.copy()"
      ],
      "id": "06194b10",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75163128"
      },
      "source": [
        "def process_part_of_data(proc_number, return_dict, ids_to_use, res_boxes, weights, params):\n",
        "    print('Start process: {} IDs to proc: {}'.format(proc_number, len(ids_to_use)))\n",
        "    result = []\n",
        "    for id in ids_to_use:\n",
        "        merged_boxes, merged_scores, merged_labels, ids_list = process_single_id(id, res_boxes, weights, params)\n",
        "        # print(merged_boxes.shape, merged_scores.shape, merged_labels.shape, len(ids_list))\n",
        "        result.append((merged_boxes, merged_scores, merged_labels, ids_list))\n",
        "    return_dict[proc_number] = result.copy()"
      ],
      "id": "75163128",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcf05c4f"
      },
      "source": [
        "def ensemble_predictions(pred_filenames, weights, params):\n",
        "    verbose = False\n",
        "    if 'verbose' in params:\n",
        "        verbose = params['verbose']\n",
        "\n",
        "    start_time = time.time()\n",
        "    procs_to_use = max(cpu_count() // 2, 1)\n",
        "    # procs_to_use = 6\n",
        "    print('Use processes: {}'.format(procs_to_use))\n",
        "    weights = np.array(weights)\n",
        "\n",
        "    res_boxes = dict()\n",
        "    ref_ids = None\n",
        "    for j in range(len(pred_filenames)):\n",
        "        if weights[j] == 0:\n",
        "            continue\n",
        "        print('Read {}...'.format(pred_filenames[j]))\n",
        "        s = pd.read_csv(pred_filenames[j], dtype={'img_id': np.str_, 'label': np.str_})\n",
        "        s.sort_values('img_id', inplace=True)\n",
        "        s.reset_index(drop=True, inplace=True)\n",
        "        ids = s['img_id'].values\n",
        "        unique_ids = sorted(s['img_id'].unique())\n",
        "        if ref_ids is None:\n",
        "            ref_ids = tuple(unique_ids)\n",
        "        else:\n",
        "            if ref_ids != tuple(unique_ids):\n",
        "                print('Different IDs in ensembled CSVs! {} != {}'.format(len(ref_ids), len(unique_ids)))\n",
        "                s = s[s['img_id'].isin(ref_ids)]\n",
        "                s.sort_values('img_id', inplace=True)\n",
        "                s.reset_index(drop=True, inplace=True)\n",
        "                ids = s['img_id'].values\n",
        "        preds = s[['x1', 'y1', 'x2', 'y2', 'score', 'label']].values\n",
        "        single_res = dict()\n",
        "        for i in range(len(ids)):\n",
        "            id = ids[i]\n",
        "            if id not in single_res:\n",
        "                single_res[id] = []\n",
        "            single_res[id].append(preds[i])\n",
        "        for el in single_res:\n",
        "            if el not in res_boxes:\n",
        "                res_boxes[el] = []\n",
        "            res_boxes[el].append(single_res[el])\n",
        "\n",
        "    # Reduce weights if needed\n",
        "    weights = weights[weights != 0]\n",
        "\n",
        "    ids_to_use = sorted(list(res_boxes.keys()))\n",
        "    manager = Manager()\n",
        "    return_dict = manager.dict()\n",
        "    jobs = []\n",
        "    for i in range(procs_to_use):\n",
        "        start = i * len(ids_to_use) // procs_to_use\n",
        "        end = (i+1) * len(ids_to_use) // procs_to_use\n",
        "        if i == procs_to_use - 1:\n",
        "            end = len(ids_to_use)\n",
        "        p = Process(target=process_part_of_data, args=(i, return_dict, ids_to_use[start:end], res_boxes, weights, params))\n",
        "        jobs.append(p)\n",
        "        p.start()\n",
        "\n",
        "    for i in range(len(jobs)):\n",
        "        jobs[i].join()\n",
        "\n",
        "    results = []\n",
        "    for i in range(len(jobs)):\n",
        "        results += return_dict[i]\n",
        "\n",
        "    # p = Pool(processes=procs_to_use)\n",
        "    # results = p.starmap(process_single_id, zip(ids_to_use, repeat(weights), repeat(params)))\n",
        "\n",
        "    all_ids = []\n",
        "    all_boxes = []\n",
        "    all_scores = []\n",
        "    all_labels = []\n",
        "    for boxes, scores, labels, ids_list in results:\n",
        "        if boxes is None:\n",
        "            continue\n",
        "        all_boxes.append(boxes)\n",
        "        all_scores.append(scores)\n",
        "        all_labels.append(labels)\n",
        "        all_ids.append(ids_list)\n",
        "\n",
        "    all_ids = np.concatenate(all_ids)\n",
        "    all_boxes = np.concatenate(all_boxes)\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "    if verbose:\n",
        "        print(all_ids.shape, all_boxes.shape, all_scores.shape, all_labels.shape)\n",
        "\n",
        "    res = pd.DataFrame(all_ids, columns=['img_id'])\n",
        "    res['x1'] = all_boxes[:, 0]\n",
        "    res['y1'] = all_boxes[:, 1]\n",
        "    res['x2'] = all_boxes[:, 2]\n",
        "    res['y2'] = all_boxes[:, 3]\n",
        "    res['score'] = all_scores\n",
        "    res['label'] = all_labels\n",
        "    print('Run time: {:.2f}'.format(time.time() - start_time))\n",
        "    return res"
      ],
      "id": "dcf05c4f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "258607c7"
      },
      "source": [
        "def ensemble(benchmark_csv, weights, params):\n",
        "\n",
        "    ensemble_preds = ensemble_predictions(benchmark_csv, weights, params)\n",
        "    ensemble_preds.to_csv(\"lrp.csv\", index=False)\n",
        "    \n",
        "    #print(benchmark_csv)\n",
        "    ap=get_coco_score(\"lrp.csv\")\n",
        "    print(\"----------------------------------------------------------\")\n",
        "    return ap"
      ],
      "id": "258607c7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c6dec19",
        "scrolled": false
      },
      "source": [
        "params = {\n",
        "            'run_type': 'wbf',\n",
        "            'skip_box_thr': 0.3,\n",
        "            'intersection_thr': 0.5,\n",
        "            'conf_type': 'avg',\n",
        "            'limit_boxes': 6000,\n",
        "            'verbose': True,\n",
        "        }"
      ],
      "id": "6c6dec19",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3agD_JaE0fE-"
      },
      "source": [
        "best_ap=None\n",
        "for L in range(1, len(csv_names)+1):\n",
        "    for subset in combinations(csv_names, L):\n",
        "        weights=list(range(1, len(subset)+1))\n",
        "        perm_weights = permutations(weights*len(subset), len(subset))\n",
        "        perm_weights = list(dict.fromkeys(perm_weights))\n",
        "        for i in list(perm_weights):\n",
        "          print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
        "          print(\"Current Parameters:\")\n",
        "          print(\"subset:\",subset)\n",
        "          print(\"weights:\",i)\n",
        "          \n",
        "          ap=ensemble(list(subset), list(i), params)\n",
        "          if best_ap  ==None:\n",
        "            best_ap=ap\n",
        "          if best_ap  !=None and ap>best_ap:\n",
        "            best_ap=ap\n",
        "            _subset=list(subset)\n",
        "            _perm_weights=str(i)\n",
        "          sub=str(subset)\n",
        "          weights=str(i)\n",
        "          header = [sub, ap, weights]\n",
        "          with open('final_ensemble.csv', 'a', encoding='UTF8') as f:\n",
        "              writer = csv.writer(f)\n",
        "              # write the header\n",
        "              writer.writerow(header)\n",
        "print(best_ap)\n",
        "print(_subset)\n",
        "print(_perm_weights)"
      ],
      "id": "3agD_JaE0fE-",
      "execution_count": null,
      "outputs": []
    }
  ]
}
